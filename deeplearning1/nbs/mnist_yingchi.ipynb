{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(1), GPU number 0 is already in use.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because MNIST is grey-scale images, it does not have the color column,\n",
    "# Let's add one empty dim  to the X data\n",
    "X_test = np.expand_dims(X_test, 1)\n",
    "X_train = np.expand_dims(X_train, 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's normalize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not we just fine-tune the imagenet model?\n",
    "\n",
    "Because imageNet is 214 x 214 and is full-color. Here we have 28 x 28 and greyscale.\n",
    "\n",
    "So we need to start from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_1 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "lm = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 14s - loss: 0.4259 - acc: 0.8735 - val_loss: 0.3073 - val_acc: 0.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf22bab400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always recommended to start with epoch 1 and a low learning rate. Defaut is 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 14s - loss: 0.2987 - acc: 0.9149 - val_loss: 0.2854 - val_acc: 0.9181\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 14s - loss: 0.2842 - acc: 0.9201 - val_loss: 0.2820 - val_acc: 0.9192\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 13s - loss: 0.2769 - acc: 0.9224 - val_loss: 0.2733 - val_acc: 0.9223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf22bab7b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr = 0.1\n",
    "lm.fit_generator(batches, batches.N, nb_epoch=3,\n",
    "                validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='softmax'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "fc = get_fc_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's start with 1 epoch and a default low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 14s - loss: 1.5465 - acc: 0.8880 - val_loss: 1.0166 - val_acc: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8ef23b9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 13s - loss: 0.2707 - acc: 0.9417 - val_loss: 0.2827 - val_acc: 0.9352\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 14s - loss: 0.2521 - acc: 0.9445 - val_loss: 0.2799 - val_acc: 0.9369\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 14s - loss: 0.2386 - acc: 0.9460 - val_loss: 0.2612 - val_acc: 0.9384\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 14s - loss: 0.2302 - acc: 0.9465 - val_loss: 0.2702 - val_acc: 0.9346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8eee00320>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.optimizer.lr=0.01\n",
    "fc.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic 'VGG-style' CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28, 28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_3 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s - loss: 0.1100 - acc: 0.9671 - val_loss: 0.0299 - val_acc: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8ed4de748>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit_generator(batches, batches.N, nb_epoch=1,\n",
    "                   validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0361 - acc: 0.9888 - val_loss: 0.0304 - val_acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf22b3d7b8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(batches, batches.N, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0232 - acc: 0.9928 - val_loss: 0.0298 - val_acc: 0.9906\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0189 - acc: 0.9938 - val_loss: 0.0332 - val_acc: 0.9901\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0146 - acc: 0.9955 - val_loss: 0.0287 - val_acc: 0.9915\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0137 - acc: 0.9953 - val_loss: 0.0196 - val_acc: 0.9934\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0349 - val_acc: 0.9917\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0103 - acc: 0.9966 - val_loss: 0.0283 - val_acc: 0.9930\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0314 - val_acc: 0.9919\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0287 - val_acc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf22b3d4a8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit_generator(batches, batches.N, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_4 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, we don't user the default settings for ImageDataGenerator\n",
    "gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s - loss: 0.1987 - acc: 0.9369 - val_loss: 0.0773 - val_acc: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8de319c88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.N, nb_epoch=1,\n",
    "                   validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 22s - loss: 0.0706 - acc: 0.9784 - val_loss: 0.0521 - val_acc: 0.9838\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 23s - loss: 0.0549 - acc: 0.9836 - val_loss: 0.0391 - val_acc: 0.9852\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 23s - loss: 0.0475 - acc: 0.9854 - val_loss: 0.0635 - val_acc: 0.9819\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 22s - loss: 0.0438 - acc: 0.9861 - val_loss: 0.0451 - val_acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8ddfad8d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(batches, batches.N, nb_epoch=4,\n",
    "                   validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 23s - loss: 0.0397 - acc: 0.9882 - val_loss: 0.0376 - val_acc: 0.9888\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 23s - loss: 0.0365 - acc: 0.9884 - val_loss: 0.0356 - val_acc: 0.9891\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0405 - val_acc: 0.9877\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0320 - acc: 0.9899 - val_loss: 0.0281 - val_acc: 0.9908\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0304 - acc: 0.9901 - val_loss: 0.0301 - val_acc: 0.9907\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0278 - acc: 0.9911 - val_loss: 0.0321 - val_acc: 0.9897\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 22s - loss: 0.0285 - acc: 0.9906 - val_loss: 0.0289 - val_acc: 0.9901\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 23s - loss: 0.0271 - acc: 0.9917 - val_loss: 0.0350 - val_acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8ec05fba8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit_generator(batches, batches.N, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchnorm + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn():\n",
    "    model = Sequential([\n",
    "            Lambda(norm_input, input_shape=(1,28,28)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            MaxPooling2D(),\n",
    "            BatchNormalization(axis=1),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            MaxPooling2D(),\n",
    "            Flatten(),\n",
    "            BatchNormalization(),\n",
    "            Dense(512, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_6 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 33s - loss: 0.1643 - acc: 0.9502 - val_loss: 0.0628 - val_acc: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8cedd7a20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_bn()\n",
    "model.fit_generator(batches, batches.N, nb_epoch=1,\n",
    "                   validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 33s - loss: 0.0700 - acc: 0.9781 - val_loss: 0.0534 - val_acc: 0.9836\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 33s - loss: 0.0604 - acc: 0.9817 - val_loss: 0.0532 - val_acc: 0.9835\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 32s - loss: 0.0528 - acc: 0.9835 - val_loss: 0.0387 - val_acc: 0.9876\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 32s - loss: 0.0466 - acc: 0.9849 - val_loss: 0.0372 - val_acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8ce1952b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(batches, batches.N, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0458 - acc: 0.9855 - val_loss: 0.0332 - val_acc: 0.9886\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0408 - acc: 0.9874 - val_loss: 0.0336 - val_acc: 0.9897\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0394 - acc: 0.9874 - val_loss: 0.0324 - val_acc: 0.9897\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0372 - acc: 0.9890 - val_loss: 0.0436 - val_acc: 0.9868\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0344 - acc: 0.9893 - val_loss: 0.0358 - val_acc: 0.9888\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 33s - loss: 0.0320 - acc: 0.9899 - val_loss: 0.0420 - val_acc: 0.9861\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0309 - acc: 0.9906 - val_loss: 0.0295 - val_acc: 0.9899\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 33s - loss: 0.0309 - acc: 0.9901 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 31s - loss: 0.0280 - acc: 0.9911 - val_loss: 0.0326 - val_acc: 0.9905\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0278 - acc: 0.9914 - val_loss: 0.0203 - val_acc: 0.9937\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0279 - acc: 0.9914 - val_loss: 0.0266 - val_acc: 0.9914\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0294 - val_acc: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8cdcf6390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.001\n",
    "model.fit_generator(batches, batches.N, nb_epoch=12, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchnorm + dropout + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_7 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model_bn_do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.2491 - acc: 0.9341 - val_loss: 0.1253 - val_acc: 0.9624\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 33s - loss: 0.1139 - acc: 0.9672 - val_loss: 0.0875 - val_acc: 0.9750\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0986 - acc: 0.9708 - val_loss: 0.0978 - val_acc: 0.9682\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0986 - acc: 0.9718 - val_loss: 0.0581 - val_acc: 0.9825\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 33s - loss: 0.0900 - acc: 0.9746 - val_loss: 0.0687 - val_acc: 0.9799\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0933 - acc: 0.9742 - val_loss: 0.0656 - val_acc: 0.9822\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 33s - loss: 0.0897 - acc: 0.9758 - val_loss: 0.0466 - val_acc: 0.9862\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0873 - acc: 0.9759 - val_loss: 0.0655 - val_acc: 0.9857\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0863 - acc: 0.9768 - val_loss: 0.0660 - val_acc: 0.9831\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0830 - acc: 0.9782 - val_loss: 0.0462 - val_acc: 0.9873\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 33s - loss: 0.0876 - acc: 0.9780 - val_loss: 0.0709 - val_acc: 0.9835\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 32s - loss: 0.0800 - acc: 0.9787 - val_loss: 0.0430 - val_acc: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8c9da4828>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit_generator(batches, batches.N, nb_epoch=12, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembling is a way that can often improve your accuracy. It takes many models and combines them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model_bn_do()\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=1, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    model.optimizer.lr=0.1\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=4, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    model.optimizer.lr=0.01\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=12, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    # model.optimizer.lr=0.001\n",
    "    # model.fit_generator(batches, batches.N, nb_epoch=18, verbose=0,\n",
    "    #                    validation_data=test_batches, nb_val_samples=test_batches.N)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_9 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_10 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_11 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_12 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_13 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/keras/layers/core.py:577: UserWarning: `output_shape` argument not specified for layer lambda_14 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "# Return a list of models\n",
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/mnist/'\n",
    "model_path = path + 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist23-'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0158,  0.9952])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10000, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])\n",
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.996999979019165, dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_accuracy(y_test, avg_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
